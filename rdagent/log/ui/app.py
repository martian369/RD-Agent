"""
RD-Agent Streamlit UI åº”ç”¨

è¿™æ˜¯ä¸€ä¸ªåŸºäº Streamlit çš„å¯è§†åŒ–ç•Œé¢ï¼Œç”¨äºå±•ç¤º RD-Agent çš„è¿è¡Œæ—¥å¿—å’Œå®éªŒç»“æœã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æ˜¾ç¤ºå®éªŒåœºæ™¯æè¿°
2. å±•ç¤ºç ”ç©¶å‡è®¾å’Œåé¦ˆ
3. å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–
4. æ˜¾ç¤ºä»£ç æ¼”åŒ–è¿‡ç¨‹
5. æä¾›ä»»åŠ¡å®Œæˆæƒ…å†µåˆ†æ

ä½œè€…ï¼šRD-Agent å›¢é˜Ÿ
"""

import argparse
import re
import textwrap
from collections import defaultdict
from datetime import datetime, timezone
from importlib.resources import files as rfiles
from pathlib import Path
from typing import Callable, Type

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots
from streamlit import session_state as state
from streamlit_theme import st_theme

from rdagent.components.coder.factor_coder.evaluators import FactorSingleFeedback
from rdagent.components.coder.factor_coder.factor import FactorFBWorkspace, FactorTask
from rdagent.components.coder.model_coder.evaluators import ModelSingleFeedback
from rdagent.components.coder.model_coder.model import ModelFBWorkspace, ModelTask
from rdagent.core.proposal import Hypothesis, HypothesisFeedback
from rdagent.core.scenario import Scenario
from rdagent.log.base import Message
from rdagent.log.storage import FileStorage
from rdagent.log.ui.qlib_report_figure import report_figure
from rdagent.scenarios.general_model.scenario import GeneralModelScenario
from rdagent.scenarios.kaggle.experiment.scenario import KGScenario
from rdagent.scenarios.qlib.experiment.factor_experiment import QlibFactorScenario
from rdagent.scenarios.qlib.experiment.factor_from_report_experiment import (
    QlibFactorFromReportScenario,
)
from rdagent.scenarios.qlib.experiment.model_experiment import (
    QlibModelExperiment,
    QlibModelScenario,
)
from rdagent.scenarios.qlib.experiment.quant_experiment import QlibQuantScenario

# è®¾ç½®Streamlité¡µé¢é…ç½®
st.set_page_config(layout="wide", page_title="RD-Agent", page_icon="ğŸ“", initial_sidebar_state="expanded")


# è·å–å‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description="RD-Agent Streamlit App")
parser.add_argument("--log_dir", type=str, help="æ—¥å¿—ç›®å½•è·¯å¾„")
parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
args = parser.parse_args()
if args.log_dir:
    main_log_path = Path(args.log_dir)
    if not main_log_path.exists():
        st.error(f"æ—¥å¿—ç›®å½• `{main_log_path}` ä¸å­˜åœ¨!")
        st.stop()
else:
    main_log_path = None


# Qlibé€‰å®šçš„æŒ‡æ ‡
QLIB_SELECTED_METRICS = [
    "IC",
    "1day.excess_return_with_cost.annualized_return",
    "1day.excess_return_with_cost.information_ratio",
    "1day.excess_return_with_cost.max_drawdown",
]

# ç›¸ä¼¼çš„åœºæ™¯ç±»å‹
SIMILAR_SCENARIOS = (
    QlibModelScenario,
    QlibFactorScenario,
    QlibFactorFromReportScenario,
    QlibQuantScenario,
    KGScenario,
)


def filter_log_folders(main_log_path):
    """
    è¿‡æ»¤å¹¶è¿”å›ç›¸å¯¹äºä¸»æ—¥å¿—è·¯å¾„çš„æ—¥å¿—æ–‡ä»¶å¤¹
    
    è¯¥å‡½æ•°ç”¨äºç­›é€‰æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼Œå¹¶æŒ‰åç§°æ’åºè¿”å›ç›¸å¯¹è·¯å¾„åˆ—è¡¨ã€‚
    ä¸»è¦ç”¨äºåœ¨UIä¸­æ˜¾ç¤ºå¯ç”¨çš„æ—¥å¿—ç›®å½•ä¾›ç”¨æˆ·é€‰æ‹©ã€‚
    
    Parameters:
        main_log_path: ä¸»æ—¥å¿—è·¯å¾„
        
    Returns:
        list: æ’åºåçš„æ—¥å¿—æ–‡ä»¶å¤¹åˆ—è¡¨
    """
    folders = [folder.relative_to(main_log_path) for folder in main_log_path.iterdir() if folder.is_dir()]
    folders = sorted(folders, key=lambda x: x.name)
    return folders


# åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€
# ä¼šè¯çŠ¶æ€ç”¨äºåœ¨ç”¨æˆ·ä¸åº”ç”¨äº¤äº’æ—¶ä¿æŒæ•°æ®
if "log_path" not in state:
    if main_log_path:
        state.log_path = filter_log_folders(main_log_path)[0]
    else:
        state.log_path = None
        st.toast(":red[**è¯·è®¾ç½®æ—¥å¿—è·¯å¾„!**]", icon="âš ï¸")

if "scenario" not in state:
    state.scenario = None

if "fs" not in state:
    state.fs = None

if "msgs" not in state:
    state.msgs = defaultdict(lambda: defaultdict(list))

if "last_msg" not in state:
    state.last_msg = None

if "current_tags" not in state:
    state.current_tags = []

if "lround" not in state:
    state.lround = 0  # RDå¾ªç¯è½®æ¬¡

if "erounds" not in state:
    state.erounds = defaultdict(int)  # æ¯ä¸ªRDå¾ªç¯ä¸­çš„æ¼”åŒ–è½®æ¬¡

if "e_decisions" not in state:
    state.e_decisions = defaultdict(lambda: defaultdict(tuple))

# æ‘˜è¦ä¿¡æ¯
if "hypotheses" not in state:
    # æ¯ä¸ªRDå¾ªç¯ä¸­çš„å‡è®¾
    state.hypotheses = defaultdict(None)

if "h_decisions" not in state:
    state.h_decisions = defaultdict(bool)

if "metric_series" not in state:
    state.metric_series = []

if "all_metric_series" not in state:
    state.all_metric_series = []

# å› å­ä»»åŠ¡åŸºçº¿
if "alpha_baseline_metrics" not in state:
    state.alpha_baseline_metrics = None

# æ’é™¤æ ‡ç­¾å’Œç±»å‹
if "excluded_tags" not in state:
    state.excluded_tags = ["llm_messages"]  # é»˜è®¤æ’é™¤llm_messagesæ ‡ç­¾

if "excluded_types" not in state:
    state.excluded_types = []


def should_display(msg: Message):
    """
    åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦åº”è¯¥æ˜¾ç¤º
    
    Parameters:
        msg: æ¶ˆæ¯å¯¹è±¡
        
    Returns:
        bool: æ˜¯å¦åº”è¯¥æ˜¾ç¤º
    """
    for t in state.excluded_tags + ["debug_tpl", "debug_llm"]:
        if t in msg.tag.split("."):
            return False

    if type(msg.content).__name__ in state.excluded_types:
        return False

    return True


def get_msgs_until(end_func: Callable[[Message], bool] = lambda _: True):
    """
    è·å–æ¶ˆæ¯ç›´åˆ°æ»¡è¶³ç»“æŸæ¡ä»¶
    
    Parameters:
        end_func: ç»“æŸæ¡ä»¶å‡½æ•°
    """
    if state.fs:
        while True:
            try:
                msg = next(state.fs)
                if should_display(msg):
                    tags = msg.tag.split(".")
                    if "hypothesis generation" in msg.tag:
                        state.lround += 1

                    # æ–°åœºæ™¯ç”Ÿæˆè¿™äº›æ ‡ç­¾ï¼Œæ—§ç‰ˆæœ¬UIæ²¡æœ‰è¿™äº›æ ‡ç­¾
                    msg.tag = re.sub(r"\.evo_loop_\d+", "", msg.tag)
                    msg.tag = re.sub(r"Loop_\d+\.[^.]+", "", msg.tag)
                    msg.tag = re.sub(r"\.\.", ".", msg.tag)

                    # ç§»é™¤æ—§çš„å†—ä½™æ ‡ç­¾
                    msg.tag = re.sub(r"init\.", "", msg.tag)
                    msg.tag = re.sub(r"r\.", "", msg.tag)
                    msg.tag = re.sub(r"d\.", "", msg.tag)
                    msg.tag = re.sub(r"ef\.", "", msg.tag)

                    msg.tag = msg.tag.strip(".")

                    if "evolving code" not in state.current_tags and "evolving code" in tags:
                        state.erounds[state.lround] += 1

                    state.current_tags = tags
                    state.last_msg = msg

                    # æ›´æ–°æ‘˜è¦ä¿¡æ¯
                    if "runner result" in tags:
                        # å› å­åŸºçº¿å®éªŒæŒ‡æ ‡
                        if (
                            isinstance(state.scenario, (QlibFactorScenario, QlibQuantScenario))
                            and state.alpha_baseline_metrics is None
                        ):
                            try:
                                sms = msg.content.based_experiments[0].result
                            except AttributeError:
                                sms = msg.content.based_experiments[0].__dict__["result"]
                            sms = sms.loc[QLIB_SELECTED_METRICS]
                            sms.name = "Alpha Base"
                            state.alpha_baseline_metrics = sms

                        if state.lround == 1 and len(msg.content.based_experiments) > 0:
                            try:
                                sms = msg.content.based_experiments[-1].result
                            except AttributeError:
                                sms = msg.content.based_experiments[-1].__dict__["result"]
                            if sms is not None:
                                if isinstance(
                                    state.scenario,
                                    (
                                        QlibModelScenario,
                                        QlibFactorFromReportScenario,
                                        QlibFactorScenario,
                                        QlibQuantScenario,
                                    ),
                                ):
                                    sms_all = sms
                                    sms = sms.loc[QLIB_SELECTED_METRICS]
                                sms.name = f"Baseline"
                                state.metric_series.append(sms)
                                state.all_metric_series.append(sms_all)

                        # é€šç”¨æŒ‡æ ‡
                        try:
                            sms = msg.content.result
                        except AttributeError:
                            sms = msg.content.__dict__["result"]
                        if isinstance(
                            state.scenario,
                            (
                                QlibModelScenario,
                                QlibFactorFromReportScenario,
                                QlibFactorScenario,
                                QlibQuantScenario,
                            ),
                        ):
                            sms_all = sms
                            sms = sms.loc[QLIB_SELECTED_METRICS]

                        sms.name = f"Round {state.lround}"
                        sms_all.name = f"Round {state.lround}"
                        state.metric_series.append(sms)
                        state.all_metric_series.append(sms_all)
                    elif "hypothesis generation" in tags:
                        state.hypotheses[state.lround] = msg.content
                    elif "evolving code" in tags:
                        msg.content = [i for i in msg.content if i]
                    elif "evolving feedback" in tags:
                        total_len = len(msg.content)
                        none_num = total_len - len(msg.content)
                        right_num = 0
                        for wsf in msg.content:
                            if wsf.final_decision:
                                right_num += 1
                        wrong_num = len(msg.content) - right_num
                        state.e_decisions[state.lround][state.erounds[state.lround]] = (
                            right_num,
                            wrong_num,
                            none_num,
                        )
                    elif "feedback" in tags and isinstance(msg.content, HypothesisFeedback):
                        state.h_decisions[state.lround] = msg.content.decision

                    state.msgs[state.lround][msg.tag].append(msg)

                    # åœæ­¢è·å–æ—¥å¿—
                    if end_func(msg):
                        break
            except StopIteration:
                st.toast(":red[**æ²¡æœ‰æ›´å¤šæ—¥å¿—å¯æ˜¾ç¤º!**]", icon="ğŸ›‘")
                break


def refresh(same_trace: bool = False):
    """
    åˆ·æ–°æ—¥å¿—æ•°æ®
    
    Parameters:
        same_trace: æ˜¯å¦ä½¿ç”¨ç›¸åŒè½¨è¿¹
    """
    if state.log_path is None:
        st.toast(":red[**è¯·è®¾ç½®æ—¥å¿—è·¯å¾„!**]", icon="âš ï¸")
        return

    if main_log_path:
        state.fs = FileStorage(main_log_path / state.log_path).iter_msg()
    else:
        state.fs = FileStorage(state.log_path).iter_msg()

    # æ£€æµ‹åœºæ™¯
    if not same_trace:
        get_msgs_until(lambda m: isinstance(m.content, Scenario))
        if state.last_msg is None or not isinstance(state.last_msg.content, Scenario):
            st.write(state.msgs)
            st.toast(":red[**æœªæ£€æµ‹åˆ°åœºæ™¯ä¿¡æ¯**]", icon="â—")
            state.scenario = None
        else:
            state.scenario = state.last_msg.content
            st.toast(f":green[**æ£€æµ‹åˆ°åœºæ™¯ä¿¡æ¯**] *{type(state.scenario).__name__}*", icon="âœ…")

    state.msgs = defaultdict(lambda: defaultdict(list))
    state.lround = 0
    state.erounds = defaultdict(int)
    state.e_decisions = defaultdict(lambda: defaultdict(tuple))
    state.hypotheses = defaultdict(None)
    state.h_decisions = defaultdict(bool)
    state.metric_series = []
    state.all_metric_series = []
    state.last_msg = None
    state.current_tags = []
    state.alpha_baseline_metrics = None


def evolving_feedback_window(wsf: FactorSingleFeedback | ModelSingleFeedback):
    """
    æ˜¾ç¤ºæ¼”åŒ–åé¦ˆçª—å£
    
    Parameters:
        wsf: å› å­æˆ–æ¨¡å‹çš„å•ä¸€åé¦ˆå¯¹è±¡
    """
    if isinstance(wsf, FactorSingleFeedback):
        ffc, efc, cfc, vfc = st.tabs(
            ["**æœ€ç»ˆåé¦ˆğŸ**", "æ‰§è¡Œåé¦ˆğŸ–¥ï¸", "ä»£ç åé¦ˆğŸ“„", "æ•°å€¼åé¦ˆğŸ”¢"]
        )
        with ffc:
            st.markdown(wsf.final_feedback)
        with efc:
            st.code(wsf.execution_feedback, language="log")
        with cfc:
            st.markdown(wsf.code_feedback)
        with vfc:
            st.markdown(wsf.value_feedback)
    elif isinstance(wsf, ModelSingleFeedback):
        ffc, efc, cfc, msfc, vfc = st.tabs(
            [
                "**æœ€ç»ˆåé¦ˆğŸ**",
                "æ‰§è¡Œåé¦ˆğŸ–¥ï¸",
                "ä»£ç åé¦ˆğŸ“„",
                "æ¨¡å‹å½¢çŠ¶åé¦ˆğŸ“",
                "æ•°å€¼åé¦ˆğŸ”¢",
            ]
        )
        with ffc:
            st.markdown(wsf.final_feedback)
        with efc:
            st.code(wsf.execution_feedback, language="log")
        with cfc:
            st.markdown(wsf.code_feedback)
        with msfc:
            st.markdown(wsf.shape_feedback)
        with vfc:
            st.markdown(wsf.value_feedback)


def display_hypotheses(hypotheses: dict[int, Hypothesis], decisions: dict[int, bool], success_only: bool = False):
    """
    æ˜¾ç¤ºå‡è®¾ä¿¡æ¯
    
    Parameters:
        hypotheses: å‡è®¾å­—å…¸
        decisions: å†³ç­–å­—å…¸
        success_only: æ˜¯å¦åªæ˜¾ç¤ºæˆåŠŸçš„å‡è®¾
    """
    name_dict = {
        "hypothesis": "RD-Agentæå‡ºçš„å‡è®¾â¬‡ï¸",
        "concise_justification": "å› ä¸ºåŸå› â¬‡ï¸",
        "concise_observation": "åŸºäºè§‚å¯Ÿâ¬‡ï¸",
        "concise_knowledge": "å®è·µåè·å¾—çš„çŸ¥è¯†â¬‡ï¸",
    }
    if success_only:
        shd = {k: v.__dict__ for k, v in hypotheses.items() if decisions[k]}
    else:
        shd = {k: v.__dict__ for k, v in hypotheses.items()}
    df = pd.DataFrame(shd).T

    if "concise_observation" in df.columns and "concise_justification" in df.columns:
        df["concise_observation"], df["concise_justification"] = df["concise_justification"], df["concise_observation"]
        df.rename(
            columns={"concise_observation": "concise_justification", "concise_justification": "concise_observation"},
            inplace=True,
        )
    if "reason" in df.columns:
        df.drop(["reason"], axis=1, inplace=True)
    if "concise_reason" in df.columns:
        df.drop(["concise_reason"], axis=1, inplace=True)

    df.columns = df.columns.map(lambda x: name_dict.get(x, x))
    for col in list(df.columns):
        if all([value is None for value in df[col]]):
            df.drop([col], axis=1, inplace=True)

    def style_rows(row):
        if decisions[row.name]:
            return ["color: green;"] * len(row)
        return [""] * len(row)

    def style_columns(col):
        if col.name != name_dict.get("hypothesis", "hypothesis"):
            return ["font-style: italic;"] * len(col)
        return ["font-weight: bold;"] * len(col)

    # st.dataframe(df.style.apply(style_rows, axis=1).apply(style_columns, axis=0))
    st.markdown(df.style.apply(style_rows, axis=1).apply(style_columns, axis=0).to_html(), unsafe_allow_html=True)


def metrics_window(df: pd.DataFrame, R: int, C: int, *, height: int = 300, colors: list[str] = None):
    """
    æ˜¾ç¤ºæŒ‡æ ‡çª—å£
    
    Parameters:
        df: æ•°æ®æ¡†
        R: è¡Œæ•°
        C: åˆ—æ•°
        height: å›¾è¡¨é«˜åº¦
        colors: é¢œè‰²åˆ—è¡¨
    """
    fig = make_subplots(rows=R, cols=C, subplot_titles=df.columns)

    def hypothesis_hover_text(h: Hypothesis, d: bool = False):
        color = "green" if d else "black"
        text = h.hypothesis
        lines = textwrap.wrap(text, width=60)
        return f"<span style='color: {color};'>{'<br>'.join(lines)}</span>"

    hover_texts = [
        hypothesis_hover_text(state.hypotheses[int(i[6:])], state.h_decisions[int(i[6:])])
        for i in df.index
        if i != "Alpha Base" and i != "Baseline"
    ]
    if state.alpha_baseline_metrics is not None:
        hover_texts = ["Baseline"] + hover_texts
    for ci, col in enumerate(df.columns):
        row = ci // C + 1
        col_num = ci % C + 1
        fig.add_trace(
            go.Scatter(
                x=df.index,
                y=df[col],
                name=col,
                mode="lines+markers",
                connectgaps=True,
                marker=dict(size=10, color=colors[ci]) if colors else dict(size=10),
                hovertext=hover_texts,
                hovertemplate="%{hovertext}<br><br><span style='color: black'>%{x} å€¼:</span> <span style='color: blue'>%{y}</span><extra></extra>",
            ),
            row=row,
            col=col_num,
        )
    fig.update_layout(showlegend=False, height=height)

    if state.alpha_baseline_metrics is not None:
        for i in range(1, R + 1):  # è¡Œ
            for j in range(1, C + 1):  # åˆ—
                fig.update_xaxes(
                    tickvals=[df.index[0]] + list(df.index[1:]),
                    ticktext=[f'<span style="color:blue; font-weight:bold">{df.index[0]}</span>'] + list(df.index[1:]),
                    row=i,
                    col=j,
                )
    st.plotly_chart(fig)

    from io import BytesIO

    buffer = BytesIO()
    df.to_csv(buffer)
    buffer.seek(0)
    st.download_button(label="ä¸‹è½½æŒ‡æ ‡ (csv)", data=buffer, file_name="metrics.csv", mime="text/csv")


def summary_window():
    """
    æ˜¾ç¤ºæ‘˜è¦çª—å£
    """
    if isinstance(state.scenario, SIMILAR_SCENARIOS):
        st.header("æ‘˜è¦ğŸ“Š", divider="rainbow", anchor="_summary")
        if state.lround == 0:
            return
        with st.container():
            # TODO: not fixed height
            with st.container():
                bc, cc = st.columns([2, 2], vertical_alignment="center")
                with bc:
                    st.subheader("æŒ‡æ ‡ğŸ“ˆ", anchor="_metrics")
                with cc:
                    show_true_only = st.toggle("æˆåŠŸçš„å‡è®¾", value=False)

            # hypotheses_c, chart_c = st.columns([2, 3])
            chart_c = st.container()
            hypotheses_c = st.container()

            with hypotheses_c:
                st.subheader("å‡è®¾ğŸ…", anchor="_hypotheses")
                display_hypotheses(state.hypotheses, state.h_decisions, show_true_only)

            with chart_c:
                if isinstance(state.scenario, QlibFactorScenario) and state.alpha_baseline_metrics is not None:
                    df = pd.DataFrame([state.alpha_baseline_metrics] + state.metric_series[1:])
                elif isinstance(state.scenario, QlibQuantScenario) and state.alpha_baseline_metrics is not None:
                    df = pd.DataFrame([state.alpha_baseline_metrics] + state.metric_series[1:])
                else:
                    df = pd.DataFrame(state.metric_series)
                if show_true_only and len(state.hypotheses) >= len(state.metric_series):
                    if state.alpha_baseline_metrics is not None:
                        selected = ["Alpha Base"] + [
                            i for i in df.index if i == "Baseline" or (i.startswith("Round ") and state.h_decisions[int(i[6:])])
                        ]
                    else:
                        selected = [i for i in df.index if i == "Baseline" or (i.startswith("Round ") and state.h_decisions[int(i[6:])])]
                    df = df.loc[selected]
                if df.shape[0] == 1:
                    st.table(df.iloc[0])
                elif df.shape[0] > 1:
                    if df.shape[1] == 1:
                        fig = px.line(df, x=df.index, y=df.columns, markers=True)
                        fig.update_layout(xaxis_title="å¾ªç¯è½®æ¬¡", yaxis_title=None)
                        st.plotly_chart(fig)
                    else:
                        metrics_window(df, 1, 4, height=300, colors=["red", "blue", "orange", "green"])

    elif isinstance(state.scenario, GeneralModelScenario):
        with st.container(border=True):
            st.subheader("æ‘˜è¦ğŸ“Š", divider="rainbow", anchor="_summary")
            if len(state.msgs[state.lround]["evolving code"]) > 0:
                # pass
                ws: list[FactorFBWorkspace | ModelFBWorkspace] = state.msgs[state.lround]["evolving code"][-1].content
                # æ‰€æœ‰ä»»åŠ¡

                tab_names = [
                    w.target_task.factor_name if isinstance(w.target_task, FactorTask) else w.target_task.name
                    for w in ws
                ]
                for j in range(len(ws)):
                    if state.msgs[state.lround]["evolving feedback"][-1].content[j].final_decision:
                        tab_names[j] += "âœ”ï¸"
                    else:
                        tab_names[j] += "âŒ"

                wtabs = st.tabs(tab_names)
                for j, w in enumerate(ws):
                    with wtabs[j]:
                        # æ¼”åŒ–ä»£ç 
                        for k, v in w.file_dict.items():
                            with st.expander(f":green[`{k}`]", expanded=False):
                                st.code(v, language="python")

                        # æ¼”åŒ–åé¦ˆ
                        evolving_feedback_window(state.msgs[state.lround]["evolving feedback"][-1].content[j])


def tabs_hint():
    """
    æ˜¾ç¤ºæ ‡ç­¾é¡µæç¤º
    """
    st.markdown(
        "<p style='font-size: small; color: #888888;'>æ‚¨å¯ä»¥ä½¿ç”¨ â¬…ï¸ â¡ï¸ æˆ–æŒ‰ä½Shiftå¹¶ç”¨é¼ æ ‡æ»šè½®ğŸ–±ï¸åœ¨æ ‡ç­¾é¡µé—´å¯¼èˆªã€‚</p>",
        unsafe_allow_html=True,
    )


def tasks_window(tasks: list[FactorTask | ModelTask]):
    """
    æ˜¾ç¤ºä»»åŠ¡çª—å£
    
    Parameters:
        tasks: ä»»åŠ¡åˆ—è¡¨
    """
    if isinstance(tasks[0], FactorTask):
        st.markdown("**å› å­ä»»åŠ¡ğŸš©**")
        tnames = [f.factor_name for f in tasks]
        if sum(len(tn) for tn in tnames) > 100:
            tabs_hint()
        tabs = st.tabs(tnames)
        for i, ft in enumerate(tasks):
            with tabs[i]:
                # st.markdown(f"**å› å­åç§°**: {ft.factor_name}")
                st.markdown(f"**æè¿°**: {ft.factor_description}")
                st.latex("å…¬å¼")
                st.latex(ft.factor_formulation)

                mks = "| å˜é‡ | æè¿° |\n| --- | --- |\n"
                if isinstance(ft.variables, dict):
                    for v, d in ft.variables.items():
                        mks += f"| ${v}$ | {d} |\n"
                    st.markdown(mks)

    elif isinstance(tasks[0], ModelTask):
        st.markdown("**æ¨¡å‹ä»»åŠ¡ğŸš©**")
        tnames = [m.name for m in tasks]
        if sum(len(tn) for tn in tnames) > 100:
            tabs_hint()
        tabs = st.tabs(tnames)
        for i, mt in enumerate(tasks):
            with tabs[i]:
                # st.markdown(f"**æ¨¡å‹åç§°**: {mt.name}")
                st.markdown(f"**æ¨¡å‹ç±»å‹**: {mt.model_type}")
                st.markdown(f"**æè¿°**: {mt.description}")
                st.latex("å…¬å¼")
                st.latex(mt.formulation)

                mks = "| å˜é‡ | æè¿° |\n| --- | --- |\n"
                if mt.variables:
                    for v, d in mt.variables.items():
                        mks += f"| ${v}$ | {d} |\n"
                    st.markdown(mks)
                st.markdown(f"**è®­ç»ƒå‚æ•°**: {mt.training_hyperparameters}")


def research_window():
    """
    æ˜¾ç¤ºç ”ç©¶çª—å£
    """
    with st.container(border=True):
        title = "ç ”ç©¶ğŸ”" if isinstance(state.scenario, SIMILAR_SCENARIOS) else "ç ”ç©¶ğŸ” (é˜…è¯»å™¨)"
        st.subheader(title, divider="blue", anchor="_research")
        if isinstance(state.scenario, SIMILAR_SCENARIOS):
            # pdfå›¾åƒ
            if pim := state.msgs[round]["load_pdf_screenshot"]:
                for i in range(min(2, len(pim))):
                    st.image(pim[i].content, use_container_width=True)

            # å‡è®¾
            if hg := state.msgs[round]["hypothesis generation"]:
                st.markdown("**å‡è®¾ğŸ’¡**")  # ğŸ§ 
                h: Hypothesis = hg[0].content
                st.markdown(
                    f"""
- **å‡è®¾**: {h.hypothesis}
- **åŸå› **: {h.reason}"""
                )

            if eg := state.msgs[round]["experiment generation"]:
                tasks_window(eg[0].content)

        elif isinstance(state.scenario, GeneralModelScenario):
            # pdfå›¾åƒ
            c1, c2 = st.columns([2, 3])
            with c1:
                if pim := state.msgs[0]["pdf_image"]:
                    for i in range(len(pim)):
                        st.image(pim[i].content, use_container_width=True)

            # åŠ è½½çš„æ¨¡å‹å®éªŒ
            with c2:
                if mem := state.msgs[0]["load_experiment"]:
                    me: QlibModelExperiment = mem[0].content
                    tasks_window(me.sub_tasks)


def feedback_window():
    """
    æ˜¾ç¤ºåé¦ˆçª—å£
    """
    # st.write(round)
    # # æ£€æŸ¥æŒ‡æ ‡åºåˆ—æ˜¯å¦å­˜åœ¨ä¸”æœ‰åŒ¹é…çš„è½®æ¬¡
    # if state.all_metric_series:
    #     for metric in state.all_metric_series:
    #         if metric.name == f"Round {round}":
    #             # é€‰æ‹©ç‰¹å®šçš„å«æˆæœ¬æŒ‡æ ‡
    #             selected_metrics_with_cost = {
    #                 'IC': float(f"{metric['IC']:.4f}"),
    #                 'ICIR': float(f"{metric['ICIR']:.4f}"),
    #                 'Rank IC': float(f"{metric['Rank IC']:.4f}"),
    #                 'Rank ICIR': float(f"{metric['Rank ICIR']:.4f}"),
    #                 'ARR': float(f"{metric['1day.excess_return_with_cost.annualized_return']:.4f}"),
    #                 'IR': float(f"{metric['1day.excess_return_with_cost.information_ratio']:.4f}"),
    #                 'MDD': float(f"{metric['1day.excess_return_with_cost.max_drawdown']:.4f}"),
    #                 'Sharpe': float(f"{metric['1day.excess_return_with_cost.annualized_return'] / abs(metric['1day.excess_return_with_cost.max_drawdown']):.4f}")
    #             }
    #             st.write("å«æˆæœ¬æŒ‡æ ‡:")
    #             st.write(pd.Series(selected_metrics_with_cost))

    #             # é€‰æ‹©ç‰¹å®šçš„ä¸å«æˆæœ¬æŒ‡æ ‡
    #             selected_metrics_without_cost = {
    #                 'IC': float(f"{metric['IC']:.4f}"),
    #                 'ICIR': float(f"{metric['ICIR']:.4f}"),
    #                 'Rank IC': float(f"{metric['Rank IC']:.4f}"),
    #                 'Rank ICIR': float(f"{metric['Rank ICIR']:.4f}"),
    #                 'ARR': float(f"{metric['1day.excess_return_without_cost.annualized_return']:.4f}"),
    #                 'IR': float(f"{metric['1day.excess_return_without_cost.information_ratio']:.4f}"),
    #                 'MDD': float(f"{metric['1day.excess_return_without_cost.max_drawdown']:.4f}"),
    #                 'Sharpe': float(f"{metric['1day.excess_return_without_cost.annualized_return'] / abs(metric['1day.excess_return_without_cost.max_drawdown']):.4f}")
    #             }
    #             st.write("ä¸å«æˆæœ¬æŒ‡æ ‡:")
    #             st.write(pd.Series(selected_metrics_without_cost))
    #             break
    if isinstance(state.scenario, SIMILAR_SCENARIOS):
        with st.container(border=True):
            st.subheader("åé¦ˆğŸ“", divider="orange", anchor="_feedback")

            if state.lround > 0 and isinstance(
                state.scenario,
                (QlibModelScenario, QlibFactorScenario, QlibFactorFromReportScenario, QlibQuantScenario, KGScenario),
            ):
                if fbr := state.msgs[round]["runner result"]:
                    try:
                        st.write("å·¥ä½œç©ºé—´")
                        st.write(fbr[0].content.experiment_workspace.workspace_path)
                        st.write(fbr[0].content.stdout)
                    except Exception as e:
                        st.error(f"æ˜¾ç¤ºå·¥ä½œç©ºé—´è·¯å¾„æ—¶å‡ºé”™: {str(e)}")
                with st.expander("**é…ç½®âš™ï¸**", expanded=True):
                    st.markdown(state.scenario.experiment_setting, unsafe_allow_html=True)

            if fb := state.msgs[round]["feedback"]:
                if fbr := state.msgs[round]["Quantitative Backtesting Chart"]:
                    st.markdown("**æ”¶ç›ŠğŸ“ˆ**")
                    fig = report_figure(fbr[0].content)
                    st.plotly_chart(fig)
                st.markdown("**å‡è®¾åé¦ˆğŸ”**")
                h: HypothesisFeedback = fb[0].content
                st.markdown(
                    f"""
- **è§‚å¯Ÿ**: {h.observations}
- **å‡è®¾è¯„ä¼°**: {h.hypothesis_evaluation}
- **æ–°å‡è®¾**: {h.new_hypothesis}
- **å†³ç­–**: {h.decision}
- **åŸå› **: {h.reason}"""
                )

            if isinstance(state.scenario, KGScenario):
                if fbe := state.msgs[round]["runner result"]:
                    submission_path = fbe[0].content.experiment_workspace.workspace_path / "submission.csv"
                    st.markdown(
                        f":green[**å®éªŒå·¥ä½œç©ºé—´**]: {str(fbe[0].content.experiment_workspace.workspace_path.absolute())}"
                    )
                    try:
                        data = submission_path.read_bytes()
                        st.download_button(
                            label="**ä¸‹è½½** submission.csv",
                            data=data,
                            file_name="submission.csv",
                            mime="text/csv",
                        )
                    except Exception as e:
                        st.markdown(f":red[**ä¸‹è½½æŒ‰é’®é”™è¯¯**]: {e}")


def evolving_window():
    """
    æ˜¾ç¤ºæ¼”åŒ–çª—å£
    """
    title = "å¼€å‘ğŸ› ï¸" if isinstance(state.scenario, SIMILAR_SCENARIOS) else "å¼€å‘ğŸ› ï¸ (æ¼”åŒ–ç¼–ç å™¨)"
    st.subheader(title, divider="green", anchor="_development")

    # æ¼”åŒ–çŠ¶æ€
    if state.erounds[round] > 0:
        st.markdown("**â˜‘ï¸ æ¼”åŒ–çŠ¶æ€**")
        es = state.e_decisions[round]
        e_status_mks = "".join(f"| {ei} " for ei in range(1, state.erounds[round] + 1)) + "|\n"
        e_status_mks += "|--" * state.erounds[round] + "|\n"
        for ei, estatus in es.items():
            if not estatus:
                estatus = (0, 0, 0)
            e_status_mks += "| " + "ğŸ•™<br>" * estatus[2] + "âœ”ï¸<br>" * estatus[0] + "âŒ<br>" * estatus[1] + " "
        e_status_mks += "|\n"
        st.markdown(e_status_mks, unsafe_allow_html=True)

    # æ¼”åŒ–æ ‡ç­¾é¡µ
    if state.erounds[round] > 0:
        if state.erounds[round] > 1:
            evolving_round = st.radio(
                "**ğŸ”„ï¸æ¼”åŒ–è½®æ¬¡**",
                horizontal=True,
                options=range(1, state.erounds[round] + 1),
                index=state.erounds[round] - 1,
                key="show_eround",
            )
        else:
            evolving_round = 1

        ws: list[FactorFBWorkspace | ModelFBWorkspace] = state.msgs[round]["evolving code"][evolving_round - 1].content
        # æ‰€æœ‰ä»»åŠ¡

        tab_names = [
            w.target_task.factor_name if isinstance(w.target_task, FactorTask) else w.target_task.name for w in ws
        ]
        if len(state.msgs[round]["evolving feedback"]) >= evolving_round:
            for j in range(len(ws)):
                if state.msgs[round]["evolving feedback"][evolving_round - 1].content[j].final_decision:
                    tab_names[j] += "âœ”ï¸"
                else:
                    tab_names[j] += "âŒ"
        if sum(len(tn) for tn in tab_names) > 100:
            tabs_hint()
        wtabs = st.tabs(tab_names)
        for j, w in enumerate(ws):
            with wtabs[j]:
                # æ¼”åŒ–ä»£ç 
                st.markdown(f"**å·¥ä½œç©ºé—´è·¯å¾„**: {w.workspace_path}")
                for k, v in w.file_dict.items():
                    with st.expander(f":green[`{k}`]", expanded=True):
                        st.code(v, language="python")

                # æ¼”åŒ–åé¦ˆ
                if len(state.msgs[round]["evolving feedback"]) >= evolving_round:
                    evolving_feedback_window(state.msgs[round]["evolving feedback"][evolving_round - 1].content[j])


toc = """
## [åœºæ™¯æè¿°ğŸ“–](#_scenario)
## [æ‘˜è¦ğŸ“Š](#_summary)
- [**æŒ‡æ ‡ğŸ“ˆ**](#_metrics)
- [**å‡è®¾ğŸ…**](#_hypotheses)
## [R&Då¾ªç¯â™¾ï¸](#_rdloops)
- [**ç ”ç©¶ğŸ”**](#_research)
- [**å¼€å‘ğŸ› ï¸**](#_development)
- [**åé¦ˆğŸ“**](#_feedback)
"""
if isinstance(state.scenario, GeneralModelScenario):
    toc = """
## [åœºæ™¯æè¿°ğŸ“–](#_scenario)
### [æ‘˜è¦ğŸ“Š](#_summary)
### [ç ”ç©¶ğŸ”](#_research)
### [å¼€å‘ğŸ› ï¸](#_development)
"""
# é…ç½®ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("# RD-AgentğŸ¤–  [:grey[@GitHub]](https://github.com/microsoft/RD-Agent)")
    st.subheader(":blue[ç›®å½•]", divider="blue")
    st.markdown(toc)
    st.subheader(":orange[æ§åˆ¶é¢æ¿]", divider="red")

    with st.container(border=True):
        if main_log_path:
            lc1, lc2 = st.columns([1, 2], vertical_alignment="center")
            with lc1:
                st.markdown(":blue[**æ—¥å¿—è·¯å¾„**]")
            with lc2:
                manually = st.toggle("æ‰‹åŠ¨è¾“å…¥")
            if manually:
                st.text_input("æ—¥å¿—è·¯å¾„", key="log_path", on_change=refresh, label_visibility="collapsed")
            else:
                folders = filter_log_folders(main_log_path)
                st.selectbox(f"**ä» `{main_log_path}` ä¸­é€‰æ‹©**", folders, key="log_path", on_change=refresh)
        else:
            st.text_input(":blue[**æ—¥å¿—è·¯å¾„**]", key="log_path", on_change=refresh)

    c1, c2 = st.columns([1, 1], vertical_alignment="center")
    with c1:
        if st.button(":green[**æ‰€æœ‰å¾ªç¯**]", use_container_width=True):
            if not state.fs:
                refresh()
            get_msgs_until(lambda m: False)
        if st.button("**é‡ç½®**", use_container_width=True):
            refresh(same_trace=True)
    with c2:
        if st.button(":green[ä¸‹ä¸€å¾ªç¯]", use_container_width=True):
            if not state.fs:
                refresh()
            get_msgs_until(lambda m: "feedback" in m.tag and "evolving feedback" not in m.tag)

        if st.button("ä¸‹ä¸€æ­¥", use_container_width=True):
            if not state.fs:
                refresh()
            get_msgs_until(lambda m: "evolving feedback" in m.tag)

    with st.popover(":orange[**é…ç½®âš™ï¸**]", use_container_width=True):
        st.multiselect("æ’é™¤çš„æ—¥å¿—æ ‡ç­¾", ["llm_messages"], ["llm_messages"], key="excluded_tags")
        st.multiselect("æ’é™¤çš„æ—¥å¿—ç±»å‹", ["str", "dict", "list"], ["str"], key="excluded_types")

    if args.debug:
        debug = st.toggle("è°ƒè¯•", value=False)

        if debug:
            if st.button("å•æ­¥è¿è¡Œ", use_container_width=True):
                get_msgs_until()
    else:
        debug = False


# è°ƒè¯•ä¿¡æ¯çª—å£
if debug:
    with st.expander(":red[**è°ƒè¯•ä¿¡æ¯**]", expanded=True):
        dcol1, dcol2 = st.columns([1, 3])
        with dcol1:
            st.markdown(
                f"**æ—¥å¿—è·¯å¾„**: {state.log_path}\n\n"
                f"**æ’é™¤æ ‡ç­¾**: {state.excluded_tags}\n\n"
                f"**æ’é™¤ç±»å‹**: {state.excluded_types}\n\n"
                f":blue[**æ¶ˆæ¯ID**]: {sum(sum(len(tmsgs) for tmsgs in rmsgs.values()) for rmsgs in state.msgs.values())}\n\n"
                f":blue[**è½®æ¬¡**]: {state.lround}\n\n"
                f":blue[**æ¼”åŒ–è½®æ¬¡**]: {state.erounds[state.lround]}\n\n"
            )
        with dcol2:
            if state.last_msg:
                st.write(state.last_msg)
                if isinstance(state.last_msg.content, list):
                    st.write(state.last_msg.content[0])
                elif isinstance(state.last_msg.content, dict):
                    st.write(state.last_msg.content)
                elif not isinstance(state.last_msg.content, str):
                    try:
                        st.write(state.last_msg.content.__dict__)
                    except:
                        st.write(type(state.last_msg.content))

if state.log_path and state.fs is None:
    refresh()

# ä¸»çª—å£
header_c1, header_c3 = st.columns([1, 6], vertical_alignment="center")
with st.container():
    with header_c1:
        st.image("https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31")
    with header_c3:
        st.markdown(
            """
        <h1>
            RD-Agent:<br>åŸºäºLLMçš„å·¥ä¸šæ•°æ®é©±åŠ¨R&Dè‡ªä¸»æ¼”åŒ–ä»£ç†
        </h1>
        """,
            unsafe_allow_html=True,
        )

# é¡¹ç›®ä¿¡æ¯
with st.container():
    image_c, scen_c = st.columns([3, 3], vertical_alignment="center")
    with image_c:
        img_path = rfiles("rdagent.log.ui").joinpath("flow.png")
        st.image(str(img_path), use_container_width=True)
    with scen_c:
        st.header("åœºæ™¯æè¿°ğŸ“–", divider="violet", anchor="_scenario")
        if state.scenario is not None:
            theme = st_theme()
            if theme:
                theme = theme.get("base", "light")
            css = f"""
<style>
    a[href="#_rdloops"], a[href="#_research"], a[href="#_development"], a[href="#_feedback"], a[href="#_scenario"], a[href="#_summary"], a[href="#_hypotheses"], a[href="#_metrics"] {{
        color: {"black" if theme == "light" else "white"};
    }}
</style>
"""
            st.markdown(state.scenario.rich_style_description + css, unsafe_allow_html=True)


def analyze_task_completion():
    """
    åˆ†æä»»åŠ¡å®Œæˆæƒ…å†µ
    """
    st.header("ä»»åŠ¡å®Œæˆæƒ…å†µåˆ†æ", divider="orange")

    # å­˜å‚¨æ‰€æœ‰å¾ªç¯ç»“æœçš„å­—å…¸
    completion_stats = {}

    # éå†æ‰€æœ‰å¾ªç¯
    for loop_round in state.msgs.keys():
        if loop_round == 0:  # è·³è¿‡åˆå§‹åŒ–å¾ªç¯
            continue

        max_evolving_round = state.erounds[loop_round]
        if max_evolving_round == 0:
            continue

        # è·Ÿè¸ªæ¯è½®æ¼”åŒ–ä¸­é€šè¿‡çš„ä»»åŠ¡
        tasks_passed_by_round = {}
        cumulative_passed = set()

        # å¯¹äºæ­¤å¾ªç¯ä¸­çš„æ¯è½®æ¼”åŒ–
        for e_round in range(1, max_evolving_round + 1):
            if len(state.msgs[loop_round]["evolving feedback"]) >= e_round:
                # è·å–æ­¤æ¼”åŒ–è½®æ¬¡çš„åé¦ˆ
                feedback = state.msgs[loop_round]["evolving feedback"][e_round - 1].content

                # è®¡ç®—é€šè¿‡çš„ä»»åŠ¡å¹¶è·Ÿè¸ªå…¶ç´¢å¼•
                passed_tasks = set()
                for j, task_feedback in enumerate(feedback):
                    if task_feedback.final_decision:
                        passed_tasks.add(j)
                        cumulative_passed.add(j)

                # å­˜å‚¨å•è½®ç»“æœå’Œç´¯ç§¯ç»“æœ
                tasks_passed_by_round[e_round] = {
                    "count": len(passed_tasks),
                    "indices": passed_tasks,
                    "cumulative_count": len(cumulative_passed),
                    "cumulative_indices": cumulative_passed.copy(),
                }

        completion_stats[loop_round] = {
            "total_tasks": len(state.msgs[loop_round]["evolving feedback"][0].content),
            "rounds": tasks_passed_by_round,
            "max_round": max_evolving_round,
        }

    # æ˜¾ç¤ºç»“æœ
    if completion_stats:
        # åœ¨é¡¶éƒ¨æ·»åŠ èšåˆè§†å›¾
        st.subheader("ğŸ”„ æ‰€æœ‰å¾ªç¯çš„èšåˆå®Œæˆæƒ…å†µ")

        # åˆ›å»ºç”¨äºæ¯”è¾ƒçš„æ‘˜è¦æ•°æ®
        summary_data = []
        total_tasks_across_loops = 0
        total_passed_r1 = 0
        total_passed_r3 = 0
        total_passed_r5 = 0
        total_passed_r10 = 0
        total_passed_final = 0

        for loop_round, stats in completion_stats.items():
            total_tasks = stats["total_tasks"]
            total_tasks_across_loops += total_tasks

            # æŸ¥æ‰¾ç‰¹å®šè½®æ¬¡çš„æ•°æ®
            r1_passed = stats["rounds"].get(1, {}).get("cumulative_count", 0)
            total_passed_r1 += r1_passed

            # å¯¹äºç¬¬3è½®ï¼Œå¦‚æœä¸å­˜åœ¨ç¡®åˆ‡çš„3åˆ™ä½¿ç”¨æœ€æ¥è¿‘çš„è½®æ¬¡
            if 3 in stats["rounds"]:
                r3_passed = stats["rounds"][3]["cumulative_count"]
            elif stats["max_round"] >= 3:
                max_r_below_3 = max([r for r in stats["rounds"].keys() if r <= 3])
                r3_passed = stats["rounds"][max_r_below_3]["cumulative_count"]
            else:
                r3_passed = stats["rounds"][stats["max_round"]]["cumulative_count"] if stats["rounds"] else 0
            total_passed_r3 += r3_passed

            # å¯¹äºç¬¬5è½®ï¼Œå¦‚æœä¸å­˜åœ¨ç¡®åˆ‡çš„5åˆ™ä½¿ç”¨æœ€æ¥è¿‘çš„è½®æ¬¡
            if 5 in stats["rounds"]:
                r5_passed = stats["rounds"][5]["cumulative_count"]
            elif stats["max_round"] >= 5:
                max_r_below_5 = max([r for r in stats["rounds"].keys() if r <= 5])
                r5_passed = stats["rounds"][max_r_below_5]["cumulative_count"]
            else:
                r5_passed = stats["rounds"][stats["max_round"]]["cumulative_count"] if stats["rounds"] else 0
            total_passed_r5 += r5_passed

            # å¯¹äºç¬¬10è½®
            if 10 in stats["rounds"]:
                r10_passed = stats["rounds"][10]["cumulative_count"]
            else:
                r10_passed = stats["rounds"][stats["max_round"]]["cumulative_count"] if stats["rounds"] else 0
            total_passed_r10 += r10_passed

            # æœ€ç»ˆè½®æ¬¡å®Œæˆæƒ…å†µ
            final_passed = stats["rounds"][stats["max_round"]]["cumulative_count"] if stats["rounds"] else 0
            total_passed_final += final_passed

            # æ·»åŠ åˆ°æ‘˜è¦è¡¨
            summary_data.append(
                {
                    "å¾ªç¯": f"å¾ªç¯ {loop_round}",
                    "æ€»ä»»åŠ¡æ•°": total_tasks,
                    "é€šè¿‡ (ç¬¬1è½®)": (
                        f"{r1_passed}/{total_tasks} ({r1_passed/total_tasks:.0%})" if total_tasks > 0 else "N/A"
                    ),
                    "é€šè¿‡ (ç¬¬3è½®)": (
                        f"{r3_passed}/{total_tasks} ({r3_passed/total_tasks:.0%})" if total_tasks > 0 else "N/A"
                    ),
                    "é€šè¿‡ (ç¬¬5è½®)": (
                        f"{r5_passed}/{total_tasks} ({r5_passed/total_tasks:.0%})" if total_tasks > 0 else "N/A"
                    ),
                    "é€šè¿‡ (æœ€ç»ˆ)": (
                        f"{final_passed}/{total_tasks} ({final_passed/total_tasks:.0%})" if total_tasks > 0 else "N/A"
                    ),
                }
            )

        if total_tasks_across_loops > 0:
            summary_data.append(
                {
                    "å¾ªç¯": "**æ€»è®¡**",
                    "æ€»ä»»åŠ¡æ•°": total_tasks_across_loops,
                    "é€šè¿‡ (ç¬¬1è½®)": f"**{total_passed_r1}/{total_tasks_across_loops} ({total_passed_r1/total_tasks_across_loops:.0%})**",
                    "é€šè¿‡ (ç¬¬3è½®)": f"**{total_passed_r3}/{total_tasks_across_loops} ({total_passed_r3/total_tasks_across_loops:.0%})**",
                    "é€šè¿‡ (ç¬¬5è½®)": f"**{total_passed_r5}/{total_tasks_across_loops} ({total_passed_r5/total_tasks_across_loops:.0%})**",
                    "é€šè¿‡ (æœ€ç»ˆ)": f"**{total_passed_final}/{total_tasks_across_loops} ({total_passed_final/total_tasks_across_loops:.0%})**",
                }
            )

        st.table(pd.DataFrame(summary_data))

        # æ‘˜è¦ç»Ÿè®¡
        st.markdown("### ğŸ“Š æ•´ä½“å®Œæˆè¿›åº¦:")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(
                label="ç¬¬1è½®å",
                value=f"{total_passed_r1/total_tasks_across_loops:.0%}",
                help=f"{total_passed_r1}/{total_tasks_across_loops} ä»»åŠ¡",
            )
        with col2:
            st.metric(
                label="ç¬¬3è½®å",
                value=f"{total_passed_r3/total_tasks_across_loops:.0%}",
                delta=f"{(total_passed_r3-total_passed_r1)/total_tasks_across_loops:.0%}",
                help=f"{total_passed_r3}/{total_tasks_across_loops} ä»»åŠ¡",
            )
        with col3:
            st.metric(
                label="ç¬¬5è½®å",
                value=f"{total_passed_r5/total_tasks_across_loops:.0%}",
                delta=f"{(total_passed_r5-total_passed_r3)/total_tasks_across_loops:.0%}",
                help=f"{total_passed_r5}/{total_tasks_across_loops} ä»»åŠ¡",
            )
        with col4:
            st.metric(
                label="æœ€ç»ˆå®Œæˆ",
                value=f"{total_passed_final/total_tasks_across_loops:.0%}",
                delta=f"{(total_passed_final-total_passed_r5)/total_tasks_across_loops:.0%}",
                help=f"{total_passed_final}/{total_tasks_across_loops} ä»»åŠ¡",
            )

        # æŒ‰å¾ªç¯æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        st.markdown("---")
        st.subheader("æŒ‰å¾ªç¯çš„è¯¦ç»†ç»“æœ")

        for loop_round, stats in completion_stats.items():
            with st.expander(f"å¾ªç¯ {loop_round} è¯¦æƒ…"):
                total_tasks = stats["total_tasks"]

                # åˆ›å»ºç»“æœè¡¨
                data = []
                for e_round in range(1, min(11, stats["max_round"] + 1)):
                    if e_round in stats["rounds"]:
                        round_data = stats["rounds"][e_round]
                        data.append(
                            {
                                "æ¼”åŒ–è½®æ¬¡": e_round,
                                "é€šè¿‡ä»»åŠ¡": f"{round_data['count']}/{total_tasks} ({round_data['count']/total_tasks:.0%})",
                                "ç´¯ç§¯é€šè¿‡": f"{round_data['cumulative_count']}/{total_tasks} ({round_data['cumulative_count']/total_tasks:.0%})",
                            }
                        )
                    else:
                        data.append({"æ¼”åŒ–è½®æ¬¡": e_round, "é€šè¿‡ä»»åŠ¡": "N/A", "ç´¯ç§¯é€šè¿‡": "N/A"})

                df = pd.DataFrame(data)
                st.table(df)

                st.markdown("### æ‘˜è¦:")
                if 1 in stats["rounds"]:
                    st.markdown(
                        f"- ç¬¬1è½®å: **{stats['rounds'][1]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][1]['cumulative_count']/total_tasks:.0%})"
                    )

                if 3 in stats["rounds"]:
                    st.markdown(
                        f"- ç¬¬3è½®å: **{stats['rounds'][3]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][3]['cumulative_count']/total_tasks:.0%})"
                    )
                elif stats["max_round"] >= 3:
                    max_round_below_3 = max([r for r in stats["rounds"].keys() if r <= 3])
                    st.markdown(
                        f"- ç¬¬3è½®å: **{stats['rounds'][max_round_below_3]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][max_round_below_3]['cumulative_count']/total_tasks:.0%})"
                    )

                if 5 in stats["rounds"]:
                    st.markdown(
                        f"- ç¬¬5è½®å: **{stats['rounds'][5]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][5]['cumulative_count']/total_tasks:.0%})"
                    )
                elif stats["max_round"] >= 5:
                    max_round_below_5 = max([r for r in stats["rounds"].keys() if r <= 5])
                    st.markdown(
                        f"- ç¬¬5è½®å: **{stats['rounds'][max_round_below_5]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][max_round_below_5]['cumulative_count']/total_tasks:.0%})"
                    )

                if 10 in stats["rounds"]:
                    st.markdown(
                        f"- ç¬¬10è½®å: **{stats['rounds'][10]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][10]['cumulative_count']/total_tasks:.0%})"
                    )
                elif stats["max_round"] >= 1:
                    st.markdown(
                        f"- æœ€ç»ˆè½®æ¬¡ ({stats['max_round']}): **{stats['rounds'][stats['max_round']]['cumulative_count']}/{total_tasks}** ä»»åŠ¡é€šè¿‡ ({stats['rounds'][stats['max_round']]['cumulative_count']/total_tasks:.0%})"
                    )
    else:
        st.info("æ²¡æœ‰ä»»åŠ¡å®Œæˆæ•°æ®å¯ç”¨ã€‚")


if state.scenario is not None:
    summary_window()
    if st.toggle("æ˜¾ç¤ºä»»åŠ¡å®Œæˆæƒ…å†µåˆ†æ"):
        analyze_task_completion()

    # R&Då¾ªç¯çª—å£
    if isinstance(state.scenario, SIMILAR_SCENARIOS):
        st.header("R&Då¾ªç¯â™¾ï¸", divider="rainbow", anchor="_rdloops")
        if len(state.msgs) > 1:
            r_options = list(state.msgs.keys())
            if 0 in r_options:
                r_options.remove(0)
            # ç¡®ä¿r_optionsä¸ä¸ºç©ºä¸”indexæœ‰æ•ˆ
            if r_options and state.lround - 1 >= 0 and state.lround - 1 < len(r_options):
                round = st.radio("**å¾ªç¯**", horizontal=True, options=r_options, index=state.lround - 1)
            elif r_options:
                # å¦‚æœindexæ— æ•ˆä½†æœ‰é€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤index 0
                round = st.radio("**å¾ªç¯**", horizontal=True, options=r_options, index=0)
            else:
                # å¦‚æœæ²¡æœ‰é€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤å€¼1
                round = 1
        else:
            round = 1

        rf_c, d_c = st.columns([2, 2])
    elif isinstance(state.scenario, GeneralModelScenario):

        rf_c = st.container()
        d_c = st.container()
        round = 0
    else:
        st.error("æœªçŸ¥åœºæ™¯!")
        st.stop()

    with rf_c:
        research_window()
        feedback_window()

    with d_c.container(border=True):
        evolving_window()


st.markdown("<br><br><br>", unsafe_allow_html=True)
st.markdown("#### å…è´£å£°æ˜")
st.markdown(
    "*æ­¤å†…å®¹ç”±AIç”Ÿæˆï¼Œå¯èƒ½ä¸å®Œå…¨å‡†ç¡®æˆ–ä¸æ˜¯æœ€æ–°çš„ï¼›å¯¹äºå…³é”®äº‹é¡¹ï¼Œè¯·ä¸ä¸“ä¸šäººå£«æ ¸å®ã€‚*",
    unsafe_allow_html=True,
)